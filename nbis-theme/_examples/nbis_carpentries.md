---
layout: "studium-page-view-2021-10-05"
title: NBIS Carpentries content
---

<article class="nbis_carpentries" markdown="1">

> ## About this episode 
> The data that you collect, organise, prepare, and analyse to answer your research questions, and the documentation describing it are the lifeblood of your research. Put bluntly: without data, there is no research. It is therefore essential that you take adequate measures to protect your data against accidental loss and against unauthorised manipulation.
> 1. TOC
> {:toc}
> {: .toc}
{: .callout .toc}

## Maintain data integrity and authenticity
Processing and analysis of data inevitably result in a number of edits in the data file. However, it is necessary to preserve the authenticity of the original research information contained in the data throughout the whole data lifecycle.

There are many possible types of changes in the data:

- Data cleaning procedures may be implemented;
- Errors are often found and corrected;
- New variables may be constructed;
- New information may be added from external sources;
- File formats may be changed;
- New data may be included;
- The data file structure may be changed for the purpose of increasing operability, etc.

As a result of above-mentioned data management processes, several different versions of the data files are usually created. They are important, as they allow you to step back to versions before particular changes were made. Versions may be used simultaneously for different purposes or replace one another. When data files are being published to make them widely available, the treatment of errors, inclusion of new data and/or changes in a data file structure may result also in the publication of new editions of the same data file which may substantially differ in their content (e.g. when new country data are included into an international data file).

Version and edition management will help to:

- Clearly distinguish between individual versions and editions and keep track of their differences;
- Prevent unauthorised modification of files and loss of information, thereby preserving data authenticity.

> ### Discussion
> What do you do to maintain data integrity and authenticity in your projects and what else could you be doing?
>> ### Examples of practices
>> Some best practice rules (UK Data Service, 2017a; Krejčí, 2014) can be summarised as follows:
>> - Establish the terms and conditions of data use and make them known to team members and other users;
>> - Create a ‘master file’ and take measures to preserve its authenticity, i.e. place it in an adequate location and define access rights and responsibilities – who is authorised to make what kind of changes;
>> - Distinguish between versions shared by researchers and working versions of individuals;
>> - Decide how many versions of a file to keep, which versions to keep (e.g. major versions rather than minor versions (keep version 02-00 but not 02-01)), for how long and how to organise versions;
>> - Introduce clear and systematic naming of data file versions and editions;
>> - Record relationships between items where needed, for example between code and the data file it is run against, between data file and related documentation or metadata or between multiple files;
>> - Document which changes were made in any version;
>> - Keep original (raw) versions of data files, or keep documentation that allows the reconstruction of original files;
>> - Track the location of files if they are stored in a variety of locations;
>> - Regularly synchronise files in different locations, such as using MS SyncToy (2016).
> {: .solution}
{: .discussion}

</article>